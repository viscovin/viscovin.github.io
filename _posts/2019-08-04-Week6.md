---
layout: post
title: Week 6
---
# Network Security

### Why do we need Network Secutrity

* Helping Host-based protections
    * Keep dangerous hosts/data out  / Create a safe space (Kindergarten rules)
    * Prevent exfiltration of critical data
    * Protect hosts missing internal protection (legacy, mobile, visitors, BYOD, IoT)
    * Hiding network traffic is different from hiding on the host (raise the bar)
* Threats come in from the network
    * DDoS
    * Attacks from the network in (e.g., Stack overflow, Morris Worm)
* Threats out ON the network
    * Worms
    * Botnets
    * Theft of network resources
    * Threat to critical infrastructure, espionage
    
### Network-based Protection Strategies
**- Positive Policy**

* Definition of what you expect/allow to happen
* Other things are suspicious and not permitted
* Why this this a fundamental concept?
    * Defender advantage, allows use of internal conventions and choices, attacker has to guess (e.g., which addresses are valid, where are the servers, critical data?)
    * Limits the attack surface (makes other kinds of protection more effective)
    * Provides a hook for other trust mechanisms: identity, trust chaining
    * Policy domain versus threat domain (finite vs. infinite enumeration)
    * However, Policy may detect a threat, but it doesn’t name the threat!!!

**- Firewalls / Security Zones**

* Most common implementation of policy is to define zones in the network with policy between the zones
* Firewalls are devices that sit between the zones and filter traffic for policy
    * Over time, more functions have been added to firewalls (e.g., Routing, NAT, IPS)
    * Firewalls are big business, almost an industry of their own
* Commonly used zones:
     Internet	  Intranet		 Testing Labs
     Extranet	  Corporate		 Data Center
     DMZ		    User Stations (DHCP Pools)
* Firewalls are best at describing policy from IPIP address.  More advanced concepts:
    * Application + IP to IP (GMAIL from User Stations to Internet)
    * User + IP to IP (Finance Worker from User Stations to Financial Data Center)

*Other Firewall-like Devices*

* Web Gateway
    * Proxies web connections to apply policy (HTTP proxy / transparent proxy)
    * On premise or in the cloud
    * URL reputation
    * Typically provides inspection of web content (JavaScript attacks, java code).  General anti-malware analysis also makes sense (e.g., file reputation, anti-virus scanning).
    * Able to leverage the interactive nature of web browsing to interact with the user (e.g., progress bars as a file is downloading to the proxy, configurable error “landing pages”).
* Email Gateway
    * Proxies SMTP connections.  Typically, the customer sets the MX record to point at the gateway’s IP address and configures the mail server IP into the gateway
    * On premise or in the cloud
    * Original mission was anti-spam (typically >99% accuracy, but there is still a lot left)
    * File scanning for malware has become equally important
    * Trending towards Data Loss Prevention (DLP)—scanning of files against dictionaries to determine if they contain secrets.

**- Defense in Depth**

<img src= "https://raw.githubusercontent.com/viscovin/viscovin.github.io/master/images/defense.JPG">

**- Intrusion Detection** 

* Intrusion detection (IDS/IPS)
    * Use signatures/anomaly detection to detect attacks
    * Extra info to use: OS type, Protocol fields, known exploit tools, packet techniques
* Advantages: 
    * Catch known attacks quickly and efficiently
    * Good information on attacks
    * Virtual patching
* Disadvantages:
    * Zero day attacks (arms race phenomenon)
    * False positives

**- Honeynets / Intrusion Deception**

* Idea: Catch the flies in honey
* Attackers don’t know the structure of the network under attack.
* We can devise a phony network to waste their time or deceive them
    * An early version of the concept appears in The Cuckoo’s Egg (Cliff Stoll, 1989).  Nova covered this true story, too (honeypot part: 39:30-44:30)
* Use unassigned internal addresses
* Apply sucker algorithms to slow down the attacker
    * E.g., wait a long time, then ack 1 byte, then repeat
* Create phony content for the attacker to download or look at.
* Problem:
    * Requires a lot of configuration per site, less common than firewalls, etc..
    * Some vendors provide solutions

**- Quarantine**

* Concept: place hosts that misbehave into a quarantine area where they can’t “infect” anyone else
* Commonly deployed on network entry
    * 801.11x switch fabrics with Network Admission Control products (not very common)
    * Airport wireless logins (very common)
    * Software Defined Networks (SDN) – new concept, getting bigger fast
* Firewalls often implement a “Blacklisting” mechanism, sort of like a quarantine
    * Behavior indicates the machine is infected or user doing something wrong (policy violations, IPS signatures, reputation)
    * Typically, black list the remote host that brought about the infection
    * A limited quarantine works better for local hosts when possible, because users don’t like to be blacklisted (remember, the user probably didn’t realize they were doing anything wrong)

**- Reputation (also host-based)**

* Big Data solution
* Collect a list of bad and good things, serve the list out from The Cloud
    * IP addresses that were associated with malware or botnets
    * IP addresses of spammers
    * URLs that reference pages with scripting attacks, drive-by-downloads, etc.
    * URL classification and categorization
    * Files that come from known program releases
    * Files that come from known viruses, or tend to be included in viruses
* McAfee GTI is a prominent example
* Issues:
    * Multi-function hosts
    * Stale data
    * Zero day susceptibility

 
