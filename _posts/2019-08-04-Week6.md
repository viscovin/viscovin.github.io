---
layout: post
title: Week 6
---
# Network Security

### Why do we need Network Secutrity

* Helping Host-based protections
    * Keep dangerous hosts/data out  / Create a safe space (Kindergarten rules)
    * Prevent exfiltration of critical data
    * Protect hosts missing internal protection (legacy, mobile, visitors, BYOD, IoT)
    * Hiding network traffic is different from hiding on the host (raise the bar)
* Threats come in from the network
    * DDoS
    * Attacks from the network in (e.g., Stack overflow, Morris Worm)
* Threats out ON the network
    * Worms
    * Botnets
    * Theft of network resources
    * Threat to critical infrastructure, espionage
    
### Network-based Protection Strategies
**- Positive Policy (Whitelisting)**

* Definition of what you expect/allow to happen
* Other things are suspicious and not permitted
* Why this this a fundamental concept?
    * Defender advantage, allows use of internal conventions and choices, attacker has to guess (e.g., which addresses are valid, where are the servers, critical data?)
    * Limits the attack surface (makes other kinds of protection more effective)
    * Provides a hook for other trust mechanisms: identity, trust chaining
    * Policy domain versus threat domain (finite vs. infinite enumeration)
    * However, Policy may detect a threat, but it doesn’t name the threat! I have to go look at what it is. 

**- Firewalls / Security Zones**

* Most common implementation of policy is to define zones in the network with policy between the zones
* Firewalls are devices that sit between the zones and filter traffic for policy
    * Over time, more functions have been added to firewalls (e.g., Routing, NAT, IPS)
    * Firewalls are big business, almost an industry of their own
* Commonly used zones:
     Internet	  Intranet		 Testing Labs
     Extranet	  Corporate		 Data Center
     DMZ		    User Stations (DHCP Pools)
* Firewalls are best at describing policy from IP<->IP address.  More advanced concepts:
    * Application + IP to IP (GMAIL from User Stations to Internet)
    * User + IP to IP (Finance Worker from User Stations to Financial Data Center)

*Other Firewall-like Devices*

* Web Gateway
    * Proxies web connections to apply policy (HTTP proxy / transparent proxy)
    * On premise or in the cloud
    * URL reputation
    * Typically provides inspection of web content (JavaScript attacks, java code).  General anti-malware analysis also makes sense (e.g., file reputation, anti-virus scanning).
    * Able to leverage the interactive nature of web browsing to interact with the user (e.g., progress bars as a file is downloading to the proxy, configurable error “landing pages”).
* Email Gateway
    * Proxies SMTP connections.  Typically, the customer sets the MX record to point at the gateway’s IP address and configures the mail server IP into the gateway
    * On premise or in the cloud
    * Original mission was anti-spam (typically >99% accuracy, but there is still a lot left)
    * File scanning for malware has become equally important
    * Trending towards Data Loss Prevention (DLP)—scanning of files against dictionaries to determine if they contain secrets.

**- Defense in Depth**

Multiple layers of defense.
<img src= "https://raw.githubusercontent.com/viscovin/viscovin.github.io/master/images/defense.JPG">

**- Intrusion Detection** 

* Intrusion detection (IDS/IPS)
    * Use signatures/anomaly detection to detect attacks
    * Extra info to use: OS type, Protocol fields, known exploit tools, packet techniques
* Advantages: 
    * Catch known attacks quickly and efficiently
    * Good information on attacks
    * Virtual patching
* Disadvantages:
    * Zero day attacks (arms race phenomenon)
    * False positives

**- Honeynets / Intrusion Deception**

* Idea: Catch the flies in honey
* Attackers don’t know the structure of the network under attack.
* We can devise a phony network to waste their time or deceive them
    * An early version of the concept appears in The Cuckoo’s Egg (Cliff Stoll, 1989).  
* Use unassigned internal addresses
* Apply sucker algorithms to slow down the attacker
    * E.g., wait a long time, then ack 1 byte, then repeat
* Create phony content for the attacker to download or look at.
* Problem:
    * Requires a lot of configuration per site, less common than firewalls, etc..
    * Some vendors provide solutions

**- Quarantine**

* Concept: place hosts that misbehave into a quarantine area where they can’t “infect” anyone else
* Commonly deployed on network entry
    * 801.11x switch fabrics with Network Admission Control products (not very common)
    * Airport wireless logins (very common)
    * Software Defined Networks (SDN) – new concept, getting bigger fast
* Firewalls often implement a “Blacklisting” mechanism, sort of like a quarantine
    * Behavior indicates the machine is infected or user doing something wrong (policy violations, IPS signatures, reputation)
    * Typically, black list the remote host that brought about the infection
    * A limited quarantine works better for local hosts when possible, because users don’t like to be blacklisted (remember, the user probably didn’t realize they were doing anything wrong)

**- Reputation (also host-based)**

* Big Data solution
* Collect a list of bad and good things, serve the list out from The Cloud
    * IP addresses that were associated with malware or botnets
    * IP addresses of spammers
    * URLs that reference pages with scripting attacks, drive-by-downloads, etc.
    * URL classification and categorization
    * Files that come from known program releases
    * Files that come from known viruses, or tend to be included in viruses
* McAfee GTI is a prominent example
* Issues:
    * Multi-function hosts
    * Stale data
    * Zero day susceptibility

### Network Security Products
- IDS -> Passive Capture + Deep Stateful Inspection + Intrusion Detection
- IPS -> IDS + Blocking traffic
- NGIPS -> IPS + Packet Filtering + Crypto Inspection + Static Analysis
- Firewall -> Packet Filtering + Deep St. Inspection + Policy
- NGFW -> Firewall + IPS + Crypto Inspection + App ID
- Web Gateway -> Proxy + Intrusion Detection + Static Analysis + Crypto Inspection + Policy
- Email Gateway -> Proxy + Intrusion Detection
- Data Loss Prevention (Data at Rest) -> Vulnerability Scanning + Intrusion Detection + Dictionary Lookups

### Man in the Middle
 
 **A <-> B and M is in the middle, intercepting and (possibly) changing messages**
 
*Example*
- Alice wants to have lunch with Bob, Alice sends Bob a message
- Unbeknownst to Alice or Bob, the evil Mallory is intercepting all messages!
- Mallory rewrites the messages.  What can she do?
    - Send Alice’ message to ask Charlie instead
    - Rewrite Bob’s message to spurn Alice, messing up their relationship
    - Rewrite Alice’ message to send Bob off to Costco to buy $50 of potato chips and rewrites Bob’s message so that Alice meets Mallory instead
    - Checks outstanding warrants, notices that Bob is a wanted felon, sicks the police on Bob while warning Alice off
**Remember:** MITM has great power for both good and evil. "With great power comes great responsability"

**Black Hat Examples** :disappointed:

* Address Resolution Protocol (ARP) Poisoning
    * Flood network with ARP responses
    * Typically: fool hosts into thinking that the Internet gateway is at your MAC address instead of the real one
* Transmission Control Protocl (TCP) hijacking
    * Inject, Delete or change data into a TCP stream (and fix up packets so no one notices)
    * Example: HTTP user logs in, then you change a transaction in a HTTP stream, add a transaction to HTTP
        * You request to withdraw $100, attacker generates a withdrawal for $1 and a check for $99 to his henchman
    * Example: SSL Renegotiate attack (advanced topic)
        * MITM intercepts initial SSL handshake request (Client Hello)
        * MITM opens SSL handshake to destination and sends initial request, followed by a renegotiation request
        * MITM lets user request proceed as renegotiation

**White Hat Examples** :smiley:

* Terminating TCP Proxy
    * Terminate TCP connections on one side, create a completely new connection on the other side
    * Rewrite all headers so that an attacker can’t transmit protocol attacks through the firewall.  Repackage TCP packets to make efficient use of packet size, remove overlapping segments, retransmissions
* HTTP Proxy
    * Intercept all HTTP traffic
    * Verify destination against list of “dangerous” hosts
    * Look for strangely encoded URLs that users normally wouldn’t use (e.g., ../ as %2e%2e%2f, or otherwise obfuscated URLs)
    * Detect and remove malicious Javascript or EXE files from remote sites from response
* Mail Proxy
    * Prevent attackers from sending EXE files
    * Look for sensitive data being exfiltrated in emails
* SSL MITM
    * Intercept SSL, decrypt and re-encrypt
    * In front of a server, by sharing the private key
    * In front of a client, by spoofing the certificate
    * Other creative ways to spoof the certificate
    * Use DNS MITM to fool the client into believing the certificate is valid

**Detection of TCP MITM**

* The trick is to use an HMAC (Crypto Hash, Pseudo Random Function), such as MD-5, (SHA-1), SHA-256, SHA-3
    * Avoid the compromised MD5 hash!!
* If each packet has a hash on it, the receiver can detect if the Man in the Middle changes the packet

**TLS Guarantees**

1. The host you connect to has the private key of the server certificate
2. The DNS name of this host, stored in the server certificate (CN=) resolves to the same IP address that you connected to
3. The connection is as hard to decrypt as the ciphersuite selected, given that the random numbers in use are cryptographically strong (i.e., impossible to predict)
4. The integrity of the data is guaranteed by as strong a hash as specified in the ciphersuite selected
5. The connection cannot be decrypted later if the server is compromised, ONLY IF the ciphersuite with perfect forward secrecy (PFS)
6. The client is guaranteed to own the secret key of the client certificate, if a client certificate is in use (approximately never)
7. The client DNS, stored in the client certificate resolves to the same IP address seen by the server (if there is a client certificate)

**TLS Vulnerabilities**

* Even though TLS is very well designed, an implement can still fail.  Take it as a lesson about the vigilance necessary to maintain cybersecurity
* In April 2014, the Heartbleed vulnerability caused a rash of TLS patching.  
    * Caused by a missing bounds check 
    * Code was checked in at 11:59pm on Dec 31, and no one read it for a long time
    * Estimated that half the servers in the Internet were vulnerable
    * No forensic evidence whether servers were actually compromised
    * Any data in the server could have been compromised, including other people’s passwords, or the server’s private key
* Heartbleed (CVE-2014-0160) is also a lesson about data separation.  If you really need to separate risks, you have to separate the data into different paths.  This is rarely done because of cost.
* We have also seen several other TLS vulnerabilities since, such as “Triple Handshake” attack, Berserk, Poodle.

## Lab 

### RECON
**Active**

- Attacker wants to attack vulnerable machines on a network
- Attacker needs to find addresses for services that can be attacked

* Basic tool is scanning—trying to connect to many hosts and services (ports)
    - Goal is to get the IP address and UDP/TCP port of a service you can attack
    - NMAP is a common tool
* Kinds of simple scans:
    - Ping (ICMP ECHO / ECHO_REPLY)
    - TCP port scan (SYN/SYNACK)
    - Other TCP scans (data/RST, FIN/RST) <- requires more state in the firewall to block
    - UDP scans (UDP data packet / ICMP Destination Unreachable)
    - Randomize the order
    - Slow scan (i.e., over months) -> hard to find without a SIEM
* Scanning for vulnerabilities
    - White hat / Black hat
    - Send an attack to a <IP,port>, see if it works, if not, try the next <IP,port>


**Passive**

- Attacker is able to see data on the network (wiring closet, ISP)
- Attacker wants to learn about people

* Getting the data
    - Tapping ISPs
    - Hiding equipment in wiring closets
    - Listening to radio signals
* “Envelope” data
    - Who is talking to alqaeda.org
        * Direct connection -> Connectivity matrix  -> Clustering
    - Passive mapping of services, like NMAP but without sending anything
    - Passive DNS
    -User name gleaning (examine logins to services on FTP, HTTP, Kerberos, certificates)
* Content
    - Web pages, files, e-mails (wireshark export command)

**RECON DEFENSES**

* Policy and Deep Inspection helps
* Honeynets can slow down reconnaissance
* Generally, these are detected using log-correlation
    - SIEM
    - IPS
    - Firewall
* It is hard to defend against passive reconnaissance, except using physical security or crypto

### Threats
**Spoofing:** Attacker masquerades as another network entity in order to gain some advantage over the network defenses of the target.

* LAND Attack: A DoS attack that relied on spoofing
* IP and ARP spoofing to perform MITM attacks
    - Used to poison ARP DBs to perform MITM
* Predictive spoofing: TCP resets, TCP sequence number prediction to get through NATs (more later)
* Legitimate uses: for load testing with large number of users
* What can be spoofed?
    - TCP sequence numbers
    - IP addresses
    - MAC addresses
    - E-mail addresses
    - HTTP fields – e.g. referrer fields
  
**Spoofing Defenses**

* Most network security solutions perform some basic checks to detect and defend against spoofing
* Reverse Path Filtering
* Ingress filtering including dropping packets from bogons
    - For more information see: RFC 3704, Ingress Filtering for Multihomed Networks
* Egress filtering to ensure that only packets that belong to appropriate internal networks (and no source IPs that belong to the network device itself) are routed through.

**Denial of Service (DOS):** About consuming resources for an extended period of time such that the targeted service is degraded, some times to a point where it is unusable

**DDoS = Distributed DoS**
 - Asymmetrical resource utilization (attackers needs to spend fewer resources than the subject of attack) is the key to the success of most DoS attacks
- DDoS leverages large numbers of computers to perform one or more resource exhaustion attacks against a target such that it is overwhelmed and unable to perform its function.
- Harder to defend against

* Motivation for a DoS attack:
    - Hacktivism
    - Financial Gain
    - Cyber War
    - Cyber Terrorism
    - Unintentional: slashdot, reddit, etc.




